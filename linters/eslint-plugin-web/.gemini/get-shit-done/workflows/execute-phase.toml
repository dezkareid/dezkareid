prompt = "<purpose>\nExecute all plans in a phase using wave-based parallel execution. Orchestrator stays lean — delegates plan execution to subagents.\n</purpose>\n\n<core_principle>\nOrchestrator coordinates, not executes. Each subagent loads the full execute-plan context. Orchestrator: discover plans → analyze deps → group waves → spawn agents → handle checkpoints → collect results.\n</core_principle>\n\n<required_reading>\nRead STATE.md before any operation to load project context.\n</required_reading>\n\n<process>\n\n<step name=\"initialize\" priority=\"first\">\nLoad all context in one call:\n\n```bash\nINIT=$(node ./.gemini/get-shit-done/bin/gsd-tools.js init execute-phase \"${PHASE_ARG}\")\n```\n\nParse JSON for: `executor_model`, `verifier_model`, `commit_docs`, `parallelization`, `branching_strategy`, `branch_name`, `phase_found`, `phase_dir`, `phase_number`, `phase_name`, `phase_slug`, `plans`, `incomplete_plans`, `plan_count`, `incomplete_count`, `state_exists`, `roadmap_exists`.\n\n**If `phase_found` is false:** Error — phase directory not found.\n**If `plan_count` is 0:** Error — no plans found in phase.\n**If `state_exists` is false but `.planning/` exists:** Offer reconstruct or continue.\n\nWhen `parallelization` is false, plans within a wave execute sequentially.\n</step>\n\n<step name=\"handle_branching\">\nCheck `branching_strategy` from init:\n\n**\"none\":** Skip, continue on current branch.\n\n**\"phase\" or \"milestone\":** Use pre-computed `branch_name` from init:\n```bash\ngit checkout -b \"$BRANCH_NAME\" 2>/dev/null || git checkout \"$BRANCH_NAME\"\n```\n\nAll subsequent commits go to this branch. User handles merging.\n</step>\n\n<step name=\"validate_phase\">\nFrom init JSON: `phase_dir`, `plan_count`, `incomplete_count`.\n\nReport: \"Found {plan_count} plans in {phase_dir} ({incomplete_count} incomplete)\"\n</step>\n\n<step name=\"discover_and_group_plans\">\nLoad plan inventory with wave grouping in one call:\n\n```bash\nPLAN_INDEX=$(node ./.gemini/get-shit-done/bin/gsd-tools.js phase-plan-index \"${PHASE_NUMBER}\")\n```\n\nParse JSON for: `phase`, `plans[]` (each with `id`, `wave`, `autonomous`, `objective`, `files_modified`, `task_count`, `has_summary`), `waves` (map of wave number → plan IDs), `incomplete`, `has_checkpoints`.\n\n**Filtering:** Skip plans where `has_summary: true`. If `--gaps-only`: also skip non-gap_closure plans. If all filtered: \"No matching incomplete plans\" → exit.\n\nReport:\n```\n## Execution Plan\n\n**Phase {X}: {Name}** — {total_plans} plans across {wave_count} waves\n\n| Wave | Plans | What it builds |\n|------|-------|----------------|\n| 1 | 01-01, 01-02 | {from plan objectives, 3-8 words} |\n| 2 | 01-03 | ... |\n```\n</step>\n\n<step name=\"execute_waves\">\nExecute each wave in sequence. Within a wave: parallel if `PARALLELIZATION=true`, sequential if `false`.\n\n**For each wave:**\n\n1. **Describe what's being built (BEFORE spawning):**\n\n   Read each plan's `<objective>`. Extract what's being built and why.\n\n   ```\n   ---\n   ## Wave {N}\n\n   **{Plan ID}: {Plan Name}**\n   {2-3 sentences: what this builds, technical approach, why it matters}\n\n   Spawning {count} agent(s)...\n   ---\n   ```\n\n   - Bad: \"Executing terrain generation plan\"\n   - Good: \"Procedural terrain generator using Perlin noise — creates height maps, biome zones, and collision meshes. Required before vehicle physics can interact with ground.\"\n\n2. **Spawn executor agents:**\n\n   Pass paths only — executors read files themselves with their fresh 200k context.\n   This keeps orchestrator context lean (~10-15%).\n\n   ```\n   Task(\n     subagent_type=\"gsd-executor\",\n     model=\"{executor_model}\",\n     prompt=\"\n       <objective>\n       Execute plan {plan_number} of phase {phase_number}-{phase_name}.\n       Commit each task atomically. Create SUMMARY.md. Update STATE.md.\n       </objective>\n\n       <execution_context>\n       @./.gemini/get-shit-done/workflows/execute-plan.md\n       @./.gemini/get-shit-done/templates/summary.md\n       @./.gemini/get-shit-done/references/checkpoints.md\n       @./.gemini/get-shit-done/references/tdd.md\n       </execution_context>\n\n       <files_to_read>\n       Read these files at execution start using the Read tool:\n       - Plan: {phase_dir}/{plan_file}\n       - State: .planning/STATE.md\n       - Config: .planning/config.json (if exists)\n       </files_to_read>\n\n       <success_criteria>\n       - [ ] All tasks executed\n       - [ ] Each task committed individually\n       - [ ] SUMMARY.md created in plan directory\n       - [ ] STATE.md updated with position and decisions\n       </success_criteria>\n     \"\n   )\n   ```\n\n3. **Wait for all agents in wave to complete.**\n\n4. **Report completion — spot-check claims first:**\n\n   For each SUMMARY.md:\n   - Verify first 2 files from `key-files.created` exist on disk\n   - Check `git log --oneline --all --grep=\"{phase}-{plan}\"` returns ≥1 commit\n   - Check for `## Self-Check: FAILED` marker\n\n   If ANY spot-check fails: report which plan failed, route to failure handler — ask \"Retry plan?\" or \"Continue with remaining waves?\"\n\n   If pass:\n   ```\n   ---\n   ## Wave {N} Complete\n\n   **{Plan ID}: {Plan Name}**\n   {What was built — from SUMMARY.md}\n   {Notable deviations, if any}\n\n   {If more waves: what this enables for next wave}\n   ---\n   ```\n\n   - Bad: \"Wave 2 complete. Proceeding to Wave 3.\"\n   - Good: \"Terrain system complete — 3 biome types, height-based texturing, physics collision meshes. Vehicle physics (Wave 3) can now reference ground surfaces.\"\n\n5. **Handle failures:**\n\n   **Known Claude Code bug (classifyHandoffIfNeeded):** If an agent reports \"failed\" with error containing `classifyHandoffIfNeeded is not defined`, this is a Claude Code runtime bug — not a GSD or agent issue. The error fires in the completion handler AFTER all tool calls finish. In this case: run the same spot-checks as step 4 (SUMMARY.md exists, git commits present, no Self-Check: FAILED). If spot-checks PASS → treat as **successful**. If spot-checks FAIL → treat as real failure below.\n\n   For real failures: report which plan failed → ask \"Continue?\" or \"Stop?\" → if continue, dependent plans may also fail. If stop, partial completion report.\n\n6. **Execute checkpoint plans between waves** — see `<checkpoint_handling>`.\n\n7. **Proceed to next wave.**\n</step>\n\n<step name=\"checkpoint_handling\">\nPlans with `autonomous: false` require user interaction.\n\n**Flow:**\n\n1. Spawn agent for checkpoint plan\n2. Agent runs until checkpoint task or auth gate → returns structured state\n3. Agent return includes: completed tasks table, current task + blocker, checkpoint type/details, what's awaited\n4. **Present to user:**\n   ```\n   ## Checkpoint: [Type]\n\n   **Plan:** 03-03 Dashboard Layout\n   **Progress:** 2/3 tasks complete\n\n   [Checkpoint Details from agent return]\n   [Awaiting section from agent return]\n   ```\n5. User responds: \"approved\"/\"done\" | issue description | decision selection\n6. **Spawn continuation agent (NOT resume)** using continuation-prompt.md template:\n   - `{completed_tasks_table}`: From checkpoint return\n   - `{resume_task_number}` + `{resume_task_name}`: Current task\n   - `{user_response}`: What user provided\n   - `{resume_instructions}`: Based on checkpoint type\n7. Continuation agent verifies previous commits, continues from resume point\n8. Repeat until plan completes or user stops\n\n**Why fresh agent, not resume:** Resume relies on internal serialization that breaks with parallel tool calls. Fresh agents with explicit state are more reliable.\n\n**Checkpoints in parallel waves:** Agent pauses and returns while other parallel agents may complete. Present checkpoint, spawn continuation, wait for all before next wave.\n</step>\n\n<step name=\"aggregate_results\">\nAfter all waves:\n\n```markdown\n## Phase {X}: {Name} Execution Complete\n\n**Waves:** {N} | **Plans:** {M}/{total} complete\n\n| Wave | Plans | Status |\n|------|-------|--------|\n| 1 | plan-01, plan-02 | ✓ Complete |\n| CP | plan-03 | ✓ Verified |\n| 2 | plan-04 | ✓ Complete |\n\n### Plan Details\n1. **03-01**: [one-liner from SUMMARY.md]\n2. **03-02**: [one-liner from SUMMARY.md]\n\n### Issues Encountered\n[Aggregate from SUMMARYs, or \"None\"]\n```\n</step>\n\n<step name=\"verify_phase_goal\">\nVerify phase achieved its GOAL, not just completed tasks.\n\n```\nTask(\n  prompt=\"Verify phase {phase_number} goal achievement.\nPhase directory: {phase_dir}\nPhase goal: {goal from ROADMAP.md}\nCheck must_haves against actual codebase. Create VERIFICATION.md.\",\n  subagent_type=\"gsd-verifier\",\n  model=\"{verifier_model}\"\n)\n```\n\nRead status:\n```bash\ngrep \"^status:\" \"$PHASE_DIR\"/*-VERIFICATION.md | cut -d: -f2 | tr -d ' '\n```\n\n| Status | Action |\n|--------|--------|\n| `passed` | → update_roadmap |\n| `human_needed` | Present items for human testing, get approval or feedback |\n| `gaps_found` | Present gap summary, offer `/gsd:plan-phase {phase} --gaps` |\n\n**If human_needed:**\n```\n## ✓ Phase {X}: {Name} — Human Verification Required\n\nAll automated checks passed. {N} items need human testing:\n\n{From VERIFICATION.md human_verification section}\n\n\"approved\" → continue | Report issues → gap closure\n```\n\n**If gaps_found:**\n```\n## ⚠ Phase {X}: {Name} — Gaps Found\n\n**Score:** {N}/{M} must-haves verified\n**Report:** {phase_dir}/{phase}-VERIFICATION.md\n\n### What's Missing\n{Gap summaries from VERIFICATION.md}\n\n---\n## ▶ Next Up\n\n`/gsd:plan-phase {X} --gaps`\n\n*(`/clear` first → fresh context window)*\n\nAlso: `cat {phase_dir}/{phase}-VERIFICATION.md` — full report\nAlso: `/gsd:verify-work {X}` — manual testing first\n```\n\nGap closure cycle: `/gsd:plan-phase {X} --gaps` reads VERIFICATION.md → creates gap plans with `gap_closure: true` → user runs `/gsd:execute-phase {X} --gaps-only` → verifier re-runs.\n</step>\n\n<step name=\"update_roadmap\">\nMark phase complete in ROADMAP.md (date, status).\n\n```bash\nnode ./.gemini/get-shit-done/bin/gsd-tools.js commit \"docs(phase-{X}): complete phase execution\" --files .planning/ROADMAP.md .planning/STATE.md .planning/phases/{phase_dir}/*-VERIFICATION.md .planning/REQUIREMENTS.md\n```\n</step>\n\n<step name=\"offer_next\">\n\n**If more phases:**\n```\n## Next Up\n\n**Phase {X+1}: {Name}** — {Goal}\n\n`/gsd:plan-phase {X+1}`\n\n*(`/clear` first for fresh context)*\n```\n\n**If milestone complete:**\n```\nMILESTONE COMPLETE!\n\nAll {N} phases executed.\n\n`/gsd:complete-milestone`\n```\n</step>\n\n</process>\n\n<context_efficiency>\nOrchestrator: ~10-15% context. Subagents: fresh 200k each. No polling (Task blocks). No context bleed.\n</context_efficiency>\n\n<failure_handling>\n- **classifyHandoffIfNeeded false failure:** Agent reports \"failed\" but error is `classifyHandoffIfNeeded is not defined` → Claude Code bug, not GSD. Spot-check (SUMMARY exists, commits present) → if pass, treat as success\n- **Agent fails mid-plan:** Missing SUMMARY.md → report, ask user how to proceed\n- **Dependency chain breaks:** Wave 1 fails → Wave 2 dependents likely fail → user chooses attempt or skip\n- **All agents in wave fail:** Systemic issue → stop, report for investigation\n- **Checkpoint unresolvable:** \"Skip this plan?\" or \"Abort phase execution?\" → record partial progress in STATE.md\n</failure_handling>\n\n<resumption>\nRe-run `/gsd:execute-phase {phase}` → discover_plans finds completed SUMMARYs → skips them → resumes from first incomplete plan → continues wave execution.\n\nSTATE.md tracks: last completed plan, current wave, pending checkpoints.\n</resumption>\n"
