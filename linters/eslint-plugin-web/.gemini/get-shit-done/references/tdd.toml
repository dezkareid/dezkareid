prompt = "<overview>\nTDD is about design quality, not coverage metrics. The red-green-refactor cycle forces you to think about behavior before implementation, producing cleaner interfaces and more testable code.\n\n**Principle:** If you can describe the behavior as `expect(fn(input)).toBe(output)` before writing `fn`, TDD improves the result.\n\n**Key insight:** TDD work is fundamentally heavier than standard tasks—it requires 2-3 execution cycles (RED → GREEN → REFACTOR), each with file reads, test runs, and potential debugging. TDD features get dedicated plans to ensure full context is available throughout the cycle.\n</overview>\n\n<when_to_use_tdd>\n## When TDD Improves Quality\n\n**TDD candidates (create a TDD plan):**\n- Business logic with defined inputs/outputs\n- API endpoints with request/response contracts\n- Data transformations, parsing, formatting\n- Validation rules and constraints\n- Algorithms with testable behavior\n- State machines and workflows\n- Utility functions with clear specifications\n\n**Skip TDD (use standard plan with `type=\"auto\"` tasks):**\n- UI layout, styling, visual components\n- Configuration changes\n- Glue code connecting existing components\n- One-off scripts and migrations\n- Simple CRUD with no business logic\n- Exploratory prototyping\n\n**Heuristic:** Can you write `expect(fn(input)).toBe(output)` before writing `fn`?\n→ Yes: Create a TDD plan\n→ No: Use standard plan, add tests after if needed\n</when_to_use_tdd>\n\n<tdd_plan_structure>\n## TDD Plan Structure\n\nEach TDD plan implements **one feature** through the full RED-GREEN-REFACTOR cycle.\n\n```markdown\n---\nphase: XX-name\nplan: NN\ntype: tdd\n---\n\n<objective>\n[What feature and why]\nPurpose: [Design benefit of TDD for this feature]\nOutput: [Working, tested feature]\n</objective>\n\n<context>\n@.planning/PROJECT.md\n@.planning/ROADMAP.md\n@relevant/source/files.ts\n</context>\n\n<feature>\n  <name>[Feature name]</name>\n  <files>[source file, test file]</files>\n  <behavior>\n    [Expected behavior in testable terms]\n    Cases: input → expected output\n  </behavior>\n  <implementation>[How to implement once tests pass]</implementation>\n</feature>\n\n<verification>\n[Test command that proves feature works]\n</verification>\n\n<success_criteria>\n- Failing test written and committed\n- Implementation passes test\n- Refactor complete (if needed)\n- All 2-3 commits present\n</success_criteria>\n\n<output>\nAfter completion, create SUMMARY.md with:\n- RED: What test was written, why it failed\n- GREEN: What implementation made it pass\n- REFACTOR: What cleanup was done (if any)\n- Commits: List of commits produced\n</output>\n```\n\n**One feature per TDD plan.** If features are trivial enough to batch, they're trivial enough to skip TDD—use a standard plan and add tests after.\n</tdd_plan_structure>\n\n<execution_flow>\n## Red-Green-Refactor Cycle\n\n**RED - Write failing test:**\n1. Create test file following project conventions\n2. Write test describing expected behavior (from `<behavior>` element)\n3. Run test - it MUST fail\n4. If test passes: feature exists or test is wrong. Investigate.\n5. Commit: `test({phase}-{plan}): add failing test for [feature]`\n\n**GREEN - Implement to pass:**\n1. Write minimal code to make test pass\n2. No cleverness, no optimization - just make it work\n3. Run test - it MUST pass\n4. Commit: `feat({phase}-{plan}): implement [feature]`\n\n**REFACTOR (if needed):**\n1. Clean up implementation if obvious improvements exist\n2. Run tests - MUST still pass\n3. Only commit if changes made: `refactor({phase}-{plan}): clean up [feature]`\n\n**Result:** Each TDD plan produces 2-3 atomic commits.\n</execution_flow>\n\n<test_quality>\n## Good Tests vs Bad Tests\n\n**Test behavior, not implementation:**\n- Good: \"returns formatted date string\"\n- Bad: \"calls formatDate helper with correct params\"\n- Tests should survive refactors\n\n**One concept per test:**\n- Good: Separate tests for valid input, empty input, malformed input\n- Bad: Single test checking all edge cases with multiple assertions\n\n**Descriptive names:**\n- Good: \"should reject empty email\", \"returns null for invalid ID\"\n- Bad: \"test1\", \"handles error\", \"works correctly\"\n\n**No implementation details:**\n- Good: Test public API, observable behavior\n- Bad: Mock internals, test private methods, assert on internal state\n</test_quality>\n\n<framework_setup>\n## Test Framework Setup (If None Exists)\n\nWhen executing a TDD plan but no test framework is configured, set it up as part of the RED phase:\n\n**1. Detect project type:**\n```bash\n# JavaScript/TypeScript\nif [ -f package.json ]; then echo \"node\"; fi\n\n# Python\nif [ -f requirements.txt ] || [ -f pyproject.toml ]; then echo \"python\"; fi\n\n# Go\nif [ -f go.mod ]; then echo \"go\"; fi\n\n# Rust\nif [ -f Cargo.toml ]; then echo \"rust\"; fi\n```\n\n**2. Install minimal framework:**\n| Project | Framework | Install |\n|---------|-----------|---------|\n| Node.js | Jest | `npm install -D jest @types/jest ts-jest` |\n| Node.js (Vite) | Vitest | `npm install -D vitest` |\n| Python | pytest | `pip install pytest` |\n| Go | testing | Built-in |\n| Rust | cargo test | Built-in |\n\n**3. Create config if needed:**\n- Jest: `jest.config.js` with ts-jest preset\n- Vitest: `vitest.config.ts` with test globals\n- pytest: `pytest.ini` or `pyproject.toml` section\n\n**4. Verify setup:**\n```bash\n# Run empty test suite - should pass with 0 tests\nnpm test  # Node\npytest    # Python\ngo test ./...  # Go\ncargo test    # Rust\n```\n\n**5. Create first test file:**\nFollow project conventions for test location:\n- `*.test.ts` / `*.spec.ts` next to source\n- `__tests__/` directory\n- `tests/` directory at root\n\nFramework setup is a one-time cost included in the first TDD plan's RED phase.\n</framework_setup>\n\n<error_handling>\n## Error Handling\n\n**Test doesn't fail in RED phase:**\n- Feature may already exist - investigate\n- Test may be wrong (not testing what you think)\n- Fix before proceeding\n\n**Test doesn't pass in GREEN phase:**\n- Debug implementation\n- Don't skip to refactor\n- Keep iterating until green\n\n**Tests fail in REFACTOR phase:**\n- Undo refactor\n- Commit was premature\n- Refactor in smaller steps\n\n**Unrelated tests break:**\n- Stop and investigate\n- May indicate coupling issue\n- Fix before proceeding\n</error_handling>\n\n<commit_pattern>\n## Commit Pattern for TDD Plans\n\nTDD plans produce 2-3 atomic commits (one per phase):\n\n```\ntest(08-02): add failing test for email validation\n\n- Tests valid email formats accepted\n- Tests invalid formats rejected\n- Tests empty input handling\n\nfeat(08-02): implement email validation\n\n- Regex pattern matches RFC 5322\n- Returns boolean for validity\n- Handles edge cases (empty, null)\n\nrefactor(08-02): extract regex to constant (optional)\n\n- Moved pattern to EMAIL_REGEX constant\n- No behavior changes\n- Tests still pass\n```\n\n**Comparison with standard plans:**\n- Standard plans: 1 commit per task, 2-4 commits per plan\n- TDD plans: 2-3 commits for single feature\n\nBoth follow same format: `{type}({phase}-{plan}): {description}`\n\n**Benefits:**\n- Each commit independently revertable\n- Git bisect works at commit level\n- Clear history showing TDD discipline\n- Consistent with overall commit strategy\n</commit_pattern>\n\n<context_budget>\n## Context Budget\n\nTDD plans target **~40% context usage** (lower than standard plans' ~50%).\n\nWhy lower:\n- RED phase: write test, run test, potentially debug why it didn't fail\n- GREEN phase: implement, run test, potentially iterate on failures\n- REFACTOR phase: modify code, run tests, verify no regressions\n\nEach phase involves reading files, running commands, analyzing output. The back-and-forth is inherently heavier than linear task execution.\n\nSingle feature focus ensures full quality throughout the cycle.\n</context_budget>\n"
